{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This assignment introduces a natural language processing task that requires classification into more than two classes, through the use of multinomial logistic regression. That task is well-known in NLP research as **named entity recognition (NER)**, which identifies and classifies named entities mentioned in unstructured text into predefined classes (e.g., person, organization, location, medicine, etc.).\n",
        "\n",
        "A complete NER task comprises taking as input an unannotated *raw* text, such as\n",
        "\n",
        "> Harry Belafonte, the popular American singer, actor, and civili rights activist, was born Harold George Bellanfanti Jr. in 1927, at Lying-in Hospital in Harlem, New York.\n",
        "\n",
        "and producing an annotated text that identifies the names and categories of the mentioned entities:\n",
        "\n",
        "> [Harry Belafonte](Type: Person), the popular American singer, actor, and civili rights activist, was born [Harold George Bellanfanti Jr.](Type: Person) in 1927, at [Lying-in Hospital](Type: Location) in [Harlem](Type: Location), [New York](Type: Location).\n"
      ],
      "metadata": {
        "id": "lSbdzf8KhGiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "You will use the data introduced by the Language-Independent Named Entity Recognition tasks, through the following body of work:\n",
        "\n",
        "* Erik F. Tjong Kim Sang and Fien De Meulder. 2003. [Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition](https://aclanthology.org/W03-0419/). In *Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003*, pages 142--147.\n",
        "* Erik F. Tjong Kim Sang. 2002. [Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition](https://aclanthology.org/W02-2024/). In *COLING-02: The 6th Conference on Natural Language Learning 2002 (CoNLL-2002)*.\n",
        "\n",
        "This assignment, however, is restricted to NER in the English language only, and the dataset consists of three files:\n",
        "\n",
        "1. `eng.train`, for training\n",
        "2. `eng.testa`, as the development set\n",
        "3. `eng.testb`, as the final test set\n",
        "\n",
        "These files can be downloaded as a single `.zip` [here](https://drive.google.com/file/d/15YEXQlDk8wvqAFOE1chaS_PYvMaLGUGX/view?usp=sharing)\n",
        "\n",
        "To avoid any complications, you should take advantage of the fact that the total amount of data is much smaller than the previous assignment, and store the entire dataset in your own Google Drive. To do this, connect your Drive to your Colab notebook:"
      ],
      "metadata": {
        "id": "_9HC9Yzin6AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "fS8B-nSbxXDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6a47f2-139f-4624-cc15-c7606da85b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, unzip the dataset (**remember to change the path to where you have stored it in your own Google drive**):"
      ],
      "metadata": {
        "id": "n9WhzU4Y0eBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/courses/cse354/eng-ner-dataset.zip"
      ],
      "metadata": {
        "id": "ycsn8ON9yh9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3d058e-cd21-4b80-c513-014392796c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/courses/cse354/eng-ner-dataset.zip\n",
            "   creating: eng-ner-dataset/\n",
            "  inflating: eng-ner-dataset/eng.testa  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/eng-ner-dataset/\n",
            "  inflating: __MACOSX/eng-ner-dataset/._eng.testa  \n",
            "  inflating: eng-ner-dataset/eng.train  \n",
            "  inflating: __MACOSX/eng-ner-dataset/._eng.train  \n",
            "  inflating: eng-ner-dataset/eng.testb  \n",
            "  inflating: __MACOSX/eng-ner-dataset/._eng.testb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, you have the unzipped corpus (with the three files) as the `eng-ner-dataset` folder accessible to your Colab notebook. The format of this data is probably new to you, so the first thing to do is to use the `head` command and see what the data looks like ([see this man page](https://www.gnu.org/software/coreutils/manual/html_node/head-invocation.html) for the details of its syntax). For example, you can view the top 20 lines of the `eng.train` file as follows:"
      ],
      "metadata": {
        "id": "MP38Yo0V0jTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 20 eng-ner-dataset/eng.train"
      ],
      "metadata": {
        "id": "k1L51bkN1Xhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b332c6-f741-4ba3-ae2b-8ed87e085661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU NNP I-NP I-ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP I-MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP I-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP I-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP I-NP I-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP I-ORG\n",
            "Commission NNP I-NP I-ORG\n",
            "said VBD I-VP O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The format you see is known as the [IOB format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)), popularly used in many NLP tasks since the CoNLL 2003 NER tasks. The file format requires\n",
        "\n",
        "- each token has to be on a separate line\n",
        "- there must be an empty line after each sentence\n",
        "- a line must contain at least two columns: first, the token itself; and the last, the named entity\n",
        "\n",
        "It doesn't matter if there are extra columns in between (perhaps containing part-of-speech tag or other information), as long as the named entity information is given in the IOB format (either IOB or IOB2).\n",
        "\n",
        "**Note:** There is a slight difference between the original IOB and IOB2 formats, and you may need to convert the training and test data to IOB2 (if you spot that some instances are using IOB while others are using IOB2)."
      ],
      "metadata": {
        "id": "rHyJwQfi29pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task Overview\n",
        "\n",
        "The programming involves three stages:\n",
        "\n",
        "1. converting the text data into feature vectors, so that it can readily be used by supervised machine learning algorithms,\n",
        "2. implement your own logistic regression classifier to identify whether or not a token is part of a person's name, and\n",
        "3. implement your own multinomial logistic regression classifier to develop a complete NER system.\n",
        "\n",
        "Throughout this assignment, remember to use type annotations in your Python code. Even if you are unable to do this for variables whose data types are dependent on external libraries that are allowed in this assignment (specified later), don't forget the type annotations for the core data types. These annotations are already provided to you in the method signatures from this point onward (to illustrate how to do this, as well as to specify the method signatures required by this assignment).\n",
        "\n",
        "* Feel free to import additional types as needed (see the line below, where a few data types are already imported for such type annotations: `from typing import ...`).\n",
        "\n",
        "#### 1.1 Importing required libraries\n",
        "- You may import modules from core Python\n",
        "- You may use any modules from `numpy` and `pandas` as long as it does not involve any 'outsourcing' of machine learning algorithms to these modules.\n",
        "\n",
        "**Do not add the following dependencies:**\n",
        "- Any module from NLTK\n",
        "- Any module from SciPy\n",
        "- Any module from scikit-learn (i.e., `sklearn`) unless it is already provided to you in this Colab notebook\n",
        "- Any library/module that performs optimizations (minimization or maximization of a function) for you. Purely numeric calculations that arise from mathematics (outside the topics in this assignment) can be done by calling numpy functions, but you must implement the stochastic gradient descent algorithm on your own.\n",
        "  - For example, computing a dot product can be done using numpy, but logits, sigmoid, softmax, etc. must be your own implementation.\n",
        "\n",
        "**What about additional methods, variables, data structures, etc.?**\n",
        "\n",
        "Throughout this assignment, you may add any number of helper methods, as you feel the need to do so. Similarly, you may use additional variables and/or data structures as the need arises. For example, if your implementation of the classifier requires you to add a class attribute, you can certainly do that.\n",
        "\n",
        "However, please keep in mind three things:\n",
        "\n",
        "1. Any external user should remain oblivious to any such additional function or variable (i.e., they should not have to assume or figure out things beyond what is already given, in order to run your code).\n",
        "2. You must update the docstring of a class if you are introducing any additional attribute.\n",
        "3. Any additional method that you write (say, a helper method) must also have a proper docstring and type hint/annotation for its signature (i.e., what data types it expects as parameters, and what data type it returns)."
      ],
      "metadata": {
        "id": "f1OkT1VS507E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation [20 points]\n",
        "\n",
        "The first step is to make sure that your code is able to read the data one sentence at a time. Given the number of sentences, and that you may have to do analyze or process each sentence in computationally complex ways, it is always prudent in this kind of work to write your code in a ways that avoids loading the entire training set. In this assignment, it may be possible, but the better option is to use the *generator* idea in Python. In this approach, the sentences are generated one at a time in a *lazy* manner (if you are more familiar with Java, think `Stream` insted of `List`)."
      ],
      "metadata": {
        "id": "EnzQvHI86ymF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, numpy, pandas\n",
        "from typing import Dict, Iterator, List, TextIO, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "UNKNOWN_TOKEN = 'UNK'  # This will be needed at times, so let's just declare it as a global constant right away\n",
        "#Used in create dataframe\n",
        "\n",
        "def load_instances(iob_file: TextIO, sep: str = '\\n') -> Iterator[str]:\n",
        "    \"\"\"\n",
        "    Load instances (which are sentences) from an input file stream.\n",
        "\n",
        "    This function reads an input file stream (`iob_file`), where tokenized sentences are provided in the IOB or IOB2\n",
        "    format, which requires each token to be on a separate line, and that there is an empty line after each sentence.\n",
        "    This empty line acts as the default separator (`sep`). Each yielded instance is a single annotated sentence (in the\n",
        "    IOB or IOB2 format, as given in the input file).\n",
        "\n",
        "    Parameters:\n",
        "        iob_file (TextIO): An input file stream containing annotated text data.\n",
        "        sep (str, optional): The separator used to separate instances. Defaults to '\\\\n'.\n",
        "\n",
        "    Yields:\n",
        "        str: A string representing a single (tokenized and annotated) sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    #Don't understand generators too well need to research how to use them, they use lazy loading and avoids whole data set\n",
        "    #Had some problems loading files this way\n",
        "\n",
        "    instancesToLoad = []\n",
        "    count = 0\n",
        "    for line in iob_file:\n",
        "      line = line.strip()\n",
        "      if line:\n",
        "        count+=1\n",
        "        instancesToLoad.append(line) #Add sentence\n",
        "      else:\n",
        "        if instancesToLoad: #Load chunk\n",
        "          yield sep.join(instancesToLoad)\n",
        "          instancesToLoad = []\n",
        "    if instancesToLoad: #Last chunck to load\n",
        "      yield sep.join(instancesToLoad)\n",
        "      #No need to clear all parsed\n",
        "\n",
        "    print('this is the load', count)\n",
        "\n"
      ],
      "metadata": {
        "id": "E92KY0zA6xVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the feature vectors will require the use of tokens seen in the training data, as well as other properties such as the part-of-speech (POS) tags of these tokens. Thus, it is imperative that all such tokens and POS tags are properly collected and tracked. The next method should help you do just that.\n",
        "\n",
        "> ---\n",
        "> **Optional features: phrasal information**\n",
        ">\n",
        "> You may have already noticed that the annotated data also contains information about the phrase containing a token (again, in IOB or IOB2 format). You are welcome to build features out of this information as well, although this is not mandated by the assignment. If you want to do this, we strongly suggest that you investigate this only *after* finishing everything else.\n",
        ">\n",
        "> *Phrasal information* is encoded as whether a token is a part of a noun phrase (NP), verb phrase (VP), prepositional phrase (PP), adjective/adverb phrases (ADJP/ADVP), verb particles (PRT), interjections (INTJ), and clauses introduced by a subordinating conjunction (SBAR).\n",
        ">\n",
        "> * If you are interested, you can read more about it [here](https://aclanthology.org/W00-0726.pdf).\n",
        ">\n",
        "> If you want to include features based on this phrase-level annotation, and want to add a third dictionary to the return type of the following function, please mention it very clearly in the docstring, and also modify the docstring to reflect this updated use of the `get_vocabulary` method.\n",
        ">\n",
        "> ---"
      ],
      "metadata": {
        "id": "GvYrxovu62fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocabulary(training_file: str) -> Tuple[Dict[str, int], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Create a vocabulary of lowercase tokens and part-of-speech (POS) tags from a training file, associating each token\n",
        "    and each POS with a unique index.\n",
        "\n",
        "    This function reads the specified training file, extracts tokens and POS tags from each sentence. It then converts\n",
        "    the tokens to lowercase, and associates each lowercase token with a unique index. It also associates each POS with\n",
        "    a unique index. The result is returned as a pair of dictionaries.\n",
        "\n",
        "    Parameters:\n",
        "        training_file (str): The path to the training file containing annotated text data.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Dict[str, int], Dict[str, int]]: A pair of dictionaries where the first dictionary consists of keys that\n",
        "        are lowercase tokens and values are their corresponding indices; and the second dictionary consists of keys that\n",
        "        are part-of-speech tags and values are their corresponding indices.\n",
        "\n",
        "    Raises:\n",
        "        IOError: If the specified training file cannot be opened or read.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenDict = {}\n",
        "    POSDict = {}\n",
        "\n",
        "    try:\n",
        "      with open(training_file, 'r') as file:\n",
        "        for line in file:\n",
        "          if line is not None:\n",
        "            line = line.split() #Split sentence into parts to seperate token and tags\n",
        "            for i, tokAndPOS in enumerate(line):\n",
        "              if i == 0 and tokAndPOS is not None: #First part is the token\n",
        "                if tokAndPOS not in tokenDict:\n",
        "                  tokenDict[tokAndPOS.lower()] = len(tokenDict) #Add to token dict\n",
        "              elif i==1 and tokAndPOS is not None: #Second part is the POS\n",
        "                if tokAndPOS not in POSDict:\n",
        "                  POSDict[tokAndPOS] = len(POSDict) #Add to POS dict\n",
        "              else:\n",
        "                break\n",
        "\n",
        "        #print(len(tokenDict))\n",
        "        return (tokenDict, POSDict)\n",
        "    except IOError as e:\n",
        "      raise IOError(f\"File couldn't be open or read: {e}\")"
      ],
      "metadata": {
        "id": "MCmSkrgS5aCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection and Data Frames\n",
        "\n",
        "The most important question to ask at this point is about the features. *What are the type of features likely to be important in the identification of various kinds of named entities?*\n",
        "\n",
        "Unsurprisingly, the token itself and its part of speech are the most important indicators. For example, a conjunction is probably not the name of a person; an adjective is probably not a part of the name of a place (assuming that the greatness of \"Great Britain\" or the length of \"Long Island\" are correctly tagged as nouns). A few other features that research in NER detection has found to be helpful are the orthographic properties of a token, which involve the patterns of capitalization (e.g., is the word in all capital letters? is it starting with a capital letter?), the POS tags of surroundings tokens, the surrounding tokens themselves, and the orthographic properties of the surrounding tokens.\n",
        "\n",
        "You are by no means restricted to use only these properties. They are provided to you as a minimal set to explore (i.e., a starting point from where you can/should explore incorporating better features).\n",
        "\n",
        "This work is what people often call **feature engineering**. It is, in some ways, \"old school\" NLP. Nevertheless, it is a relatively recent phase of NLP research, and going through this help you gain hands-on knowledge of various programming tools/approaches in NLP. It will (hopefully) also help you appreciate the complexity and utility of neural networks where such feature engineering is rarely needed.\n",
        "\n",
        "It is, of course, important to represent the training, development, and test instances using the same set of features. And for the supervised classification, we want to store the training, development, and test sets are data frames (essentially, vectors with class labels). Your next task is to complete the following method to do this.\n",
        "\n",
        "First, let's define an enumerable type so that only a fixed set of the \"kinds of data frames\" are allowed."
      ],
      "metadata": {
        "id": "5LorsrI9-uqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "class ActionType(Enum):\n",
        "    TRAIN = 'train'\n",
        "    TEST = 'test'\n",
        "    DEV = 'dev'"
      ],
      "metadata": {
        "id": "UDZIReiIDTIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this `ActionType` below:"
      ],
      "metadata": {
        "id": "4mySxjuyDs-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict #Imported ordered dict so dict stays consistent when doing one hot encodings, should be allowed since from collections library\n",
        "#import pdb used for breakpoints in colab\n",
        "\n",
        "def create_dataframe(actiontype: ActionType, output_file_name: str) -> None:\n",
        "    \"\"\"\n",
        "    Generate a pandas DataFrame from text files containing sentences (tokenized and annotated, in IOB or IOB2 format)\n",
        "    and class labels, and write the DataFrame to a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "        actiontype (ActionType): The type of action, either ActionType.TRAIN, ActionType.TEST, or ActionType.DEV.\n",
        "        output_file_name (str): The name of the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the input training or test file is not found.\n",
        "    \"\"\"\n",
        "\n",
        "    #Given action type we can choose what data set to generate a dataframe for, if wrong action or unknown action error\n",
        "    if actiontype == ActionType.TRAIN:\n",
        "      fileName = '/content/eng-ner-dataset/eng.train'\n",
        "    elif actiontype == ActionType.TEST:\n",
        "      fileName = '/content/eng-ner-dataset/eng.testb'\n",
        "    elif actiontype == ActionType.DEV:\n",
        "      fileName = '/content/eng-ner-dataset/eng.testa'\n",
        "    else:\n",
        "      raise FileNotFoundError(f\"Input file not found due to invalid action type or missing file\")\n",
        "\n",
        "    sentences = []\n",
        "    currentSentence = []\n",
        "\n",
        "    try:\n",
        "      tokenDict, POSDict = get_vocabulary('/content/eng-ner-dataset/eng.train')  #Get vocab from training set always\n",
        "\n",
        "      vocab = set(tokenDict.keys())\n",
        "      vocab.add(UNKNOWN_TOKEN) #Add unk token for when test or dev data set has vocab not in training vocab\n",
        "\n",
        "      #All possible keys to be used for one hot encoding\n",
        "      allPOS = set(POSDict.keys())\n",
        "      allCapitalization = {'allCaps', 'mixedCaps', 'noCaps'}\n",
        "      allNER = {'O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'}\n",
        "\n",
        "      #Creating a dict to store all of the features which will later turn into an one hot encoding\n",
        "      #Features used: POS, Capitalization, PREV NER, NEXT NER\n",
        "      #Also extracting NER to be used for true class labels\n",
        "      vocabFeatureClassDict = OrderedDict((word, {'POS': set(), 'Capitalization': set(), 'NER' : set(), 'PREV_NER' : set(), 'NEXT_NER': set()}) for word in vocab)\n",
        "\n",
        "      with open(fileName, 'r') as file:\n",
        "        prevLine = None\n",
        "        for line in file:\n",
        "          if line is not None:\n",
        "            line = line.split()\n",
        "            curToken = None\n",
        "            for j, tokAndPOS in enumerate(line):\n",
        "              if j == 0 and tokAndPOS is not None:\n",
        "                curToken = tokAndPOS.lower()\n",
        "                if curToken not in vocab: #If test or dev has token not in vocab make it an unknown token\n",
        "                  curToken = UNKNOWN_TOKEN\n",
        "                if tokAndPOS.isupper(): #This is where I find capital features\n",
        "                  vocabFeatureClassDict[curToken]['Capitalization'].add('allCaps')\n",
        "                elif any(char.isupper() for char in tokAndPOS):\n",
        "                  vocabFeatureClassDict[curToken]['Capitalization'].add('mixedCaps')\n",
        "                else:\n",
        "                  vocabFeatureClassDict[curToken]['Capitalization'].add('noCaps')\n",
        "              elif j==1 and tokAndPOS is not None: #This is where I find POS features\n",
        "                if curToken in vocabFeatureClassDict:\n",
        "                    vocabFeatureClassDict[curToken]['POS'].add(tokAndPOS)\n",
        "              elif j == 3 and tokAndPOS is not None: #This is where I find NER to use for classes\n",
        "                if curToken in vocabFeatureClassDict:\n",
        "                  vocabFeatureClassDict[curToken]['NER'].add(tokAndPOS)\n",
        "\n",
        "            #This is where I find PREV NER features\n",
        "            if prevLine is not None:\n",
        "              line = prevLine\n",
        "              #line = line.split()\n",
        "              if len(line) > 3 and curToken in vocabFeatureClassDict:\n",
        "                vocabFeatureClassDict[curToken]['PREV_NER'].add(line[3])\n",
        "\n",
        "            #This is where I find NEXT NER features\n",
        "            nextLine = next(file, None)\n",
        "            if nextLine is not None:\n",
        "              line = nextLine\n",
        "              line = line.split()\n",
        "              if len(line) > 3 and curToken in vocabFeatureClassDict:\n",
        "                vocabFeatureClassDict[curToken]['NEXT_NER'].add(line[3])\n",
        "\n",
        "            prevLine = line\n",
        "\n",
        "\n",
        "\n",
        "        # print(len(allPOS))\n",
        "        # print(vocabFeatureClassDict)\n",
        "\n",
        "        tokenFeatures = list(vocabFeatureClassDict.keys())\n",
        "\n",
        "        #Begin creating our pandas dataframe with tokens in first collumn features in middle and true classes at end\n",
        "        df = pandas.DataFrame({'Token': tokenFeatures})\n",
        "\n",
        "        #Added new one hot encoding can be done by following same steps for all below\n",
        "        #-------------------------------------------------------------------POS----------------------------------------------------------------------------------------\n",
        "        #Doing one hot encoding for POS\n",
        "        POSFeaturesList = []\n",
        "        #print(f'length of tokenf: {len(tokenFeatures)}')\n",
        "\n",
        "        #Had trouble with library so doing it manually and concating at end\n",
        "        for token in tokenFeatures:\n",
        "          aggEncode = numpy.zeros(len(allPOS))\n",
        "          POSTags = list(vocabFeatureClassDict[token]['POS'])\n",
        "\n",
        "          #Do one hot encoding\n",
        "\n",
        "          for POSTag in POSTags:\n",
        "            POSi = list(allPOS).index(POSTag)\n",
        "            aggEncode[POSi] = 1  #If has tag set to 1\n",
        "\n",
        "          #Store one hot encoding on pandas df arry\n",
        "          POSdf = pandas.DataFrame([aggEncode], columns=list(allPOS))\n",
        "          POSFeaturesList.append(POSdf)\n",
        "\n",
        "\n",
        "        POSdfConcat = pandas.concat(POSFeaturesList, ignore_index=True)\n",
        "\n",
        "        #Combine to full df\n",
        "        df = pandas.concat([df, POSdfConcat], axis=1)\n",
        "\n",
        "        #-----------------------------------------------------------Capitalization----------------------------------------------------------------------------------------\n",
        "        #Doing one hot encoding for Capitalization\n",
        "        capitalizationFeaturesList = []\n",
        "\n",
        "        for token in tokenFeatures:\n",
        "          aggEncode = numpy.zeros(len(allCapitalization))\n",
        "          capitalizationTags = list(vocabFeatureClassDict[token]['Capitalization'])\n",
        "\n",
        "          #Do one hot encoding\n",
        "          for capTag in capitalizationTags:\n",
        "            capi = list(allCapitalization).index(capTag)\n",
        "            aggEncode[capi] = 1 #If has tag set to 1\n",
        "\n",
        "          #Store one hot encoding on pandas df arry\n",
        "          capitalizationdf = pandas.DataFrame([aggEncode], columns=list(allCapitalization))\n",
        "          capitalizationFeaturesList.append(capitalizationdf)\n",
        "\n",
        "\n",
        "        capitalizationdfConcat = pandas.concat(capitalizationFeaturesList, ignore_index=True)\n",
        "\n",
        "        #Combine to full df\n",
        "        df = pandas.concat([df, capitalizationdfConcat], axis=1)\n",
        "\n",
        "\n",
        "        #-----------------------------------------------------------PREV and NEXT NER----------------------------------------------------------------------------------------\n",
        "        #Doing one hot encoding for PREV and NEXT NER\n",
        "        prevNERFeaturesList = []\n",
        "        nextNERFeaturesList = []\n",
        "\n",
        "        for token in tokenFeatures:\n",
        "          #PREV NER feature\n",
        "          aggEncodingPrevNER = numpy.zeros(len(allNER))\n",
        "          prevNERTags = list(vocabFeatureClassDict[token]['PREV_NER'])\n",
        "\n",
        "          #Do one hot encoding for PREV NER\n",
        "          for NERTag in prevNERTags:\n",
        "            NERi = list(allNER).index(NERTag)\n",
        "            aggEncodingPrevNER[NERi] = 1 #If has tag set to 1\n",
        "\n",
        "          #Store one hot encoding on pandas df arry\n",
        "          prevNERdf = pandas.DataFrame([aggEncodingPrevNER], columns=list(allNER))\n",
        "          prevNERFeaturesList.append(prevNERdf)\n",
        "\n",
        "          #NEXT NER feature\n",
        "          aggEncodingNextNER = numpy.zeros(len(allNER))\n",
        "          nextNERTags = list(vocabFeatureClassDict[token]['NEXT_NER'])\n",
        "\n",
        "          #Do one hot encoding for PREV NER\n",
        "          for NERTag in nextNERTags:\n",
        "            NERi = list(allNER).index(NERTag)\n",
        "            aggEncodingNextNER[NERi]= 1 #If has tag set to 1\n",
        "\n",
        "          #Store one hot encoding on pandas df arry\n",
        "          nextNERdf = pandas.DataFrame([aggEncodingNextNER], columns=list(allNER))\n",
        "          nextNERFeaturesList.append(nextNERdf)\n",
        "\n",
        "        #Combine to full df\n",
        "        prevNERdfConcat = pandas.concat(prevNERFeaturesList, ignore_index=True)\n",
        "        df = pandas.concat([df, prevNERdfConcat], axis=1)\n",
        "\n",
        "        #Combine to full df\n",
        "        nextNERdfConcat = pandas.concat(nextNERFeaturesList, ignore_index=True)\n",
        "        df = pandas.concat([df, nextNERdfConcat], axis=1)\n",
        "\n",
        "\n",
        "      #-----------------------------------------------------------NER for true classes----------------------------------------------------------------------------------------\n",
        "        NERValues = []\n",
        "\n",
        "        for token in tokenFeatures:\n",
        "          NERTags = vocabFeatureClassDict[token]['NER']\n",
        "          if NERTags:\n",
        "            NERValues.append(NERTags)\n",
        "          else: #Should never happen I think but just in case a sentence has no NER tag\n",
        "            NERValues.append('O')\n",
        "\n",
        "        #print(\"Length of NERValues:\", len(NERValues))\n",
        "        #print(\"Length of DataFrame:\", len(df))\n",
        "\n",
        "        #May need to change but alter NER tags if multiple and combines PER tags to just PER\n",
        "        #Work around\n",
        "        updatedNERValues = []\n",
        "        for tags in NERValues:\n",
        "          # if 'B-PER' in tags or 'I-PER' in tags:\n",
        "          #     updatedNERValues.append('PER')\n",
        "          # el\n",
        "          if len(tags) > 1: #Multitags assign O? Could work or just use first\n",
        "            if isinstance(tags, set):\n",
        "              updatedNERValues.append(tags.pop()) #Sometimes tags are in sets\n",
        "            else:\n",
        "              updatedNERValues.append(tags) #Sometimes tags are strings (i think when using UNK)\n",
        "          else:\n",
        "            if isinstance(tags, set):\n",
        "              updatedNERValues.append(tags.pop()) #Sometimes tags are in sets\n",
        "            else:\n",
        "              updatedNERValues.append(tags) #Sometimes tags are strings (i think when using UNK)\n",
        "\n",
        "        #Put NER values (class values) in df\n",
        "        df['NER'] = updatedNERValues\n",
        "\n",
        "        #Write df to file to be used later\n",
        "        df.to_csv(output_file_name, index=False)\n",
        "        print('SUCCESS')\n",
        "\n",
        "    except FileNotFoundError:\n",
        "      raise FileNotFoundError(f\"Input file not found due to invalid action type or missing file\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d7qZnJadD4d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_dataframe(ActionType.TRAIN, 'train_set.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-b2qb23XJ9X",
        "outputId": "6233b98c-dd76-458c-b098-de365693d766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Logistic Regression Classifier [30 points]\n",
        "\n",
        "Now that your data frames are built, it is time to build your binary logistic regression classifier to identify if a token is a part of a person's name. To do this, you can effectively treat the labels `I-PER` and `B-PER` together as a single label, `PER`, and treat all the other labels simply as *other*, denoted by `O` (how you denote it internally in your code is entirely up to you).\n",
        "\n",
        "Complete the class `BinaryLogisticRegression` below."
      ],
      "metadata": {
        "id": "sGTTAEMYFwwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "class LogisticRegressionClassifier:\n",
        "    \"\"\"\n",
        "    A binary logistic regression classifier.\n",
        "\n",
        "    Attributes:\n",
        "        learning_rate (float): The learning rate for gradient descent.\n",
        "        learning_rate_decay (float, optional): The factor by which learning rate decays with each iteration.\n",
        "        num_iterations (int): The number of iterations for gradient descent.\n",
        "        weights (ndarray): The weights for the features.\n",
        "        bias (float): The bias term.\n",
        "        training_data (pandas.DataFrame): The training data as a pandas DataFrame (to be read from a valid CSV file)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, training_data_csv: str, learning_rate=0.01, learning_rate_decay=1.0, num_iterations=1000):\n",
        "        \"\"\"\n",
        "        Initialize the logistic regression classifier.\n",
        "\n",
        "        Parameters:\n",
        "            training_data_csv (str): The file path to the CSV file containing training data.\n",
        "            learning_rate (float, optional): The learning rate for gradient descent.\n",
        "            learning_rate_decay (float, optional): The factor by which learning rate decays with each iteration.\n",
        "            num_iterations (int, optional): The number of iterations for gradient descent.\n",
        "        \"\"\"\n",
        "        try:\n",
        "          self.training_data = pandas.read_csv(training_data_csv)\n",
        "        except FileNotFoundError:\n",
        "          raise FileNotFoundError(\"File not found\")\n",
        "        self.learning_rate = learning_rate\n",
        "        self.learning_rate_decay = learning_rate_decay\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "        #May remove these but should be fine\n",
        "        self.bias = None\n",
        "        self.weights = None\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(z: float) -> float:\n",
        "        \"\"\"\n",
        "        Compute the sigmoid function.\n",
        "\n",
        "        Parameters:\n",
        "            z (float): The input to the sigmoid function.\n",
        "\n",
        "        Returns:\n",
        "            float: The output of the sigmoid function.\n",
        "        \"\"\"\n",
        "        return 1 / (1 + numpy.exp(-z))\n",
        "\n",
        "    def __to_feature_matrix(self, df: pandas.DataFrame) -> numpy.ndarray: #Changed to ndarray so I can use to transform part of df to ndarray to be used in learn and predict which take ndarrays not df\n",
        "        \"\"\"\n",
        "        A private method to extract the feature matrix from the data frame.\n",
        "\n",
        "        Parameters:\n",
        "            df (pandas.DataFrame): The given data frame.\n",
        "\n",
        "        Returns:\n",
        "            The matrix of features as a pandas DataFrame\n",
        "        \"\"\"\n",
        "        #First col is tokens and last col is classes so just use col 1 to (n-1)\n",
        "        features = df.iloc[:, 1:-1].values\n",
        "\n",
        "        return features\n",
        "\n",
        "    def __to_class_labels(self, df: pandas.DataFrame) -> numpy.ndarray: #Changed to ndarray so I can use to transform part of df to ndarray to be used in learn and predict which take ndarrays not df\n",
        "        \"\"\"\n",
        "        A private method to extract the class labels from the data frame.\n",
        "\n",
        "        Parameters:\n",
        "            df (pandas.DataFrame): The given data frame.\n",
        "\n",
        "        Returns:\n",
        "            The vector of class labels as a pandas DataFrame.\n",
        "        \"\"\"\n",
        "\n",
        "        #Use last col for classes\n",
        "        classes = df.iloc[:, -1].values\n",
        "\n",
        "        #Turn into 0 and 1 for binary classification, need to do I believe\n",
        "        classesBinary = [1 if (label == 'B-PER') or (label == 'I-PER') else 0 for label in classes]\n",
        "\n",
        "        return classesBinary\n",
        "\n",
        "    def learn(self, feature_matrix, y):\n",
        "        \"\"\"\n",
        "        Learn the weight vector to obtain the best decision boundary that separates the two classes in the training set.\n",
        "\n",
        "        It initializes the model parameters (the weights are initialized to zeros, and the bias is also initially set to\n",
        "        zero). It then performs gradient descent to optimize the parameters based on the training data. The optimization\n",
        "        is done by minimizing the cross-entropy loss or the logistic loss. The learning rate determines the step size\n",
        "        taken during gradient descent. If the decay factor is less than 1, the step size reduces with each iteration.\n",
        "\n",
        "        Parameters:\n",
        "            feature_matrix (ndarray): The feature matrix.\n",
        "            y (ndarray): The target class labels.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.weights = numpy.zeros(feature_matrix.shape[1])\n",
        "        self.bias = 0.0\n",
        "\n",
        "        #Gradient Descent with n num iterations\n",
        "        for i in range(self.num_iterations):\n",
        "          #Find probabilties through sigmoid of logits\n",
        "          logits = numpy.dot(feature_matrix, self.weights) + self.bias\n",
        "          predictions = self.sigmoid(logits)\n",
        "\n",
        "          #Get new learning rate with given decay need to add regularization as well\n",
        "          currentLearningRate = (self.learning_rate / ((self.learning_rate_decay * i) + 1))\n",
        "\n",
        "          #Find gradient and bias by calculating the between pred and true labels\n",
        "          miss = predictions - y\n",
        "          gradientBias = numpy.sum(miss)\n",
        "          gradient = numpy.dot(feature_matrix.T, miss) #Need to transpose to do dot product should be fine\n",
        "\n",
        "          #Use L1 regularization, I think it works better here for removing uneeded features\n",
        "          L1 = numpy.sign(self.weights)\n",
        "          L1Lambda = 0.01 #Starting point\n",
        "          gradient +=  L1Lambda * L1\n",
        "\n",
        "\n",
        "          #Update weights and bias using new learning rate\n",
        "          self.weights = self.weights - (gradient * currentLearningRate)\n",
        "          self.bias = self.bias - (gradientBias * currentLearningRate )\n",
        "\n",
        "        print('SUCCESS')\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, feature_matrix) -> List[int]:\n",
        "        \"\"\"\n",
        "        Predict the target labels for new/test data.\n",
        "\n",
        "        Parameters:\n",
        "            feature_matrix (ndarray): The feature matrix of new/test data.\n",
        "\n",
        "        Returns:\n",
        "            list: The predicted target labels.\n",
        "        \"\"\"\n",
        "        #Find probabilties through sigmoid of logits\n",
        "        logits = numpy.dot(feature_matrix, self.weights) + self.bias\n",
        "        probabilities = self.sigmoid(logits)\n",
        "\n",
        "        #Change threshold to alter what counts for 0 and 1\n",
        "        threshold = 0.50 #Dont need to alter for mine\n",
        "        predictions = numpy.where(probabilities < threshold, 0, 1)\n",
        "\n",
        "        return list(predictions)\n",
        "\n",
        "    def report(self, feature_matrix: numpy.ndarray, y_true: numpy.ndarray) -> Tuple[float, float, float]:\n",
        "        \"\"\"\n",
        "        Compute the precision, recall, and F-1 scores for new/test data.\n",
        "\n",
        "        Parameters:\n",
        "            feature_matrix (ndarray): The feature matrix of new/test data.\n",
        "            y_true (ndarray): The true class labels.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[float, float, float]: A tuple containing three values: the positive class' precision, recall, and F-1\n",
        "            scores (in this order)\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        #\n",
        "        # Note 1: For binary classification, we only need these three values for the positive class (instead of micro-\n",
        "        # or macro-averaging). The PER class is considered as the positive class for this component of the assignment.\n",
        "        #\n",
        "        # Note 2: You should aim for an F-1 measure of at least 0.7 on the final test set (eng.testb)\n",
        "        #F-1 is at least 0.7\n",
        "\n",
        "        #Use predict to get predictions again. May want to just save them so don't have to recompute but doesnt take long\n",
        "        predictions = self.predict(feature_matrix)\n",
        "\n",
        "        #Use sklearn.metrics to get precision recall and f1\n",
        "        precision = precision_score(y_true, predictions, average='binary')\n",
        "        recall = recall_score(y_true, predictions, average='binary')\n",
        "        f1 = f1_score(y_true, predictions, average='binary')\n",
        "\n",
        "        return (precision, recall, f1)"
      ],
      "metadata": {
        "id": "2kujxLKfICL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating all dfs\n",
        "create_dataframe(ActionType.TRAIN, 'train_set.csv')\n",
        "create_dataframe(ActionType.TEST, 'test_set.csv')\n",
        "create_dataframe(ActionType.DEV, 'dev_set.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaL2jvpyauGA",
        "outputId": "4594082e-9a5b-483d-8ff1-061384c0a7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS\n",
            "SUCCESS\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Traing models with training set\n",
        "model = LogisticRegressionClassifier(learning_rate=0.001, training_data_csv='train_set.csv', num_iterations=1000)\n",
        "\n",
        "featureMatrix = model._LogisticRegressionClassifier__to_feature_matrix(model.training_data) #Private method can be called like this\n",
        "y = model._LogisticRegressionClassifier__to_class_labels(model.training_data)\n",
        "model.learn(featureMatrix, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMNJ7D6dm1bR",
        "outputId": "e0dc88f2-5083-4e06-fdb7-35026773f31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model tests and stats reports, using another 'model' to extract information out from test, not sure if best option but works. Using DEV set\n",
        "testModel = LogisticRegressionClassifier(learning_rate=0.05, training_data_csv='dev_set.csv')\n",
        "testFeatureMatrix = testModel._LogisticRegressionClassifier__to_feature_matrix(testModel.training_data)\n",
        "testy = testModel._LogisticRegressionClassifier__to_class_labels(testModel.training_data)\n",
        "\n",
        "predictions = model.predict(testFeatureMatrix)\n",
        "model.report(testFeatureMatrix, testy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6e6-F1qm3Rl",
        "outputId": "aa989032-da5d-4d22-d76f-ebc0d62ea16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9461538461538461, 0.8848920863309353, 0.9144981412639406)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model tests and stats reports, using another 'model' to extract information out from test, not sure if best option but works. Using TEST set\n",
        "testModel = LogisticRegressionClassifier(learning_rate=0.05, training_data_csv='test_set.csv')\n",
        "testFeatureMatrix = testModel._LogisticRegressionClassifier__to_feature_matrix(testModel.training_data)\n",
        "testy = testModel._LogisticRegressionClassifier__to_class_labels(testModel.training_data)\n",
        "\n",
        "predictions = model.predict(testFeatureMatrix)\n",
        "model.report(testFeatureMatrix, testy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwDEYlrRKz1Q",
        "outputId": "3e900b31-e9ab-4f5a-b2b9-2e98cdb47941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8658892128279884, 0.8865671641791045, 0.8761061946902655)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression Classifier [30 points]\n",
        "\n",
        "This is also known as **Softmax Regression** or **Maxent Classifier**. It is a popular tool for multi-class classification, which we will use here for NER.\n",
        "\n",
        "Note that the classification is happening on a *per-token* basis, and the class labels are `B-ORG`, `I-ORG`, etc.\n",
        "\n",
        "Generalizing the binary classification task, you should complete the `MultinomialLogisticRegression` class, whose skeleton is provided to you next. For this portion, you may (optionally) import the `OneHotEncoder` or `LabelEncoder` from scikit-learn. For example, you may add this line at the beginning of the next cell:\n",
        "\n",
        "```\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "```\n"
      ],
      "metadata": {
        "id": "H4-t3y1rRAi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report #Imported for generate_report() as instructed to wrap it\n",
        "\n",
        "class MultinomialLogisticRegression:\n",
        "    \"\"\"\n",
        "    A multinomial logistic regression classifier.\n",
        "\n",
        "    Attributes:\n",
        "        learning_rate (float): The learning rate for gradient descent.\n",
        "        learning_rate_decay (float): The factor by which learning rate decays with each iteration.\n",
        "        weights (ndarray): The weights for the features.\n",
        "        bias (float): The bias term.\n",
        "        training_data (pandas.DataFrame): The training data as a pandas DataFrame (to be read from a valid CSV file)\n",
        "\n",
        "        ADDED ATTRIBUTES:\n",
        "\n",
        "        epochs (int): The number of training cycles (I think this one was forgotten in skeleton code)\n",
        "\n",
        "        trueLabels (ndarry): The true class labels for the data set\n",
        "\n",
        "        predictions (ndarry): The predicted class labels for the data set\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate: float, learning_rate_decay: float, epochs: int, training_data_csv: str):\n",
        "        \"\"\"\n",
        "        Initialize the multinomial logistic regression classifier.\n",
        "\n",
        "        Parameters:\n",
        "            learning_rate (float): The learning rate for gradient descent.\n",
        "            learning_rate_decay (float): The factor by which learning rate decays with each iteration.\n",
        "            epochs (int): The number of training epochs.\n",
        "            training_data_csv (str): The file path to the CSV file containing training data.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "          self.training_data = pandas.read_csv(training_data_csv)\n",
        "        except FileNotFoundError:\n",
        "          raise FileNotFoundError(\"File not found\")\n",
        "        self.learning_rate = learning_rate\n",
        "        self.learning_rate_decay = learning_rate_decay\n",
        "        self.epochs = epochs\n",
        "        self.bias = None\n",
        "        self.weights = None\n",
        "        self.trueLabels = None\n",
        "        self.predictions = None\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(logits):\n",
        "        \"\"\"\n",
        "        Compute the softmax function.\n",
        "\n",
        "        Parameters:\n",
        "            z (numpy.ndarray): The input to the softmax function.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: The output of the softmax function.\n",
        "        \"\"\"\n",
        "        exp_logits = numpy.exp(logits - numpy.max(logits))\n",
        "        return exp_logits / numpy.sum(exp_logits)\n",
        "\n",
        "    def learn(self) -> None:\n",
        "        \"\"\"\n",
        "        Train the multinomial logistic regression model.\n",
        "\n",
        "        This method trains the multinomial logistic regression model using stochastic gradient descent. It begins by\n",
        "        encoding the target labels into one-hot encoded vectors and initializes the weights (to zeros) for the model.\n",
        "        During each training epoch, it iterates through the training data, computing the softmax probabilities for each\n",
        "        class and updating the weights based on the gradient of the cross-entropy loss.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        # Note: Remember to use regularization, but think about what type of regularization might suit this task.\n",
        "        #Going to use L1\n",
        "        #Doing regular grad descent, confused on implementing stochastic random choice of vectors?\n",
        "\n",
        "        training_data = self.training_data\n",
        "        numTokens = len(training_data)\n",
        "        numFeatures = len(training_data.columns) - 2\n",
        "        allClassesTotal = self.training_data.iloc[:, -1]\n",
        "        numClasses = len(allClassesTotal.unique()) #All classes should be in training data\n",
        "\n",
        "        #Use weights to help with class imbalance\n",
        "        classCounts = allClassesTotal.value_counts()\n",
        "        classWeights = len(self.training_data) / (len(classCounts) * classCounts)\n",
        "        classWeightsValues = classWeights.values #Take out values cant use directly\n",
        "\n",
        "        #Init weights to 0s\n",
        "        self.weights = numpy.zeros((numFeatures, numClasses))\n",
        "\n",
        "        features = self.training_data.iloc[:,1:-1].values\n",
        "\n",
        "        #Map NER classes to ints, think I need this for multi logistic regression to work (may also need to fix PER since is combined right now)\n",
        "        classMap = {className: i for i, className in enumerate(allClassesTotal.unique())}\n",
        "        self.training_data['NERint'] = self.training_data.iloc[:, -1].map(classMap)\n",
        "        classes = self.training_data['NERint'].values\n",
        "        #print(classes) #Should be numbers 1- 7 8 ish\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "          #Find probs but logged due to size constraints\n",
        "          logits = numpy.dot(features, self.weights)\n",
        "\n",
        "          logProbs = numpy.log(self.softmax(logits))\n",
        "\n",
        "          #Compute labels using one hot, using numpy since library not working for me\n",
        "          yHot = numpy.zeros_like(logProbs)\n",
        "          yHot[numpy.arange(numTokens),classes] = 1\n",
        "          gradient = numpy.dot(features.T, (numpy.exp(logProbs)- yHot))/numTokens\n",
        "\n",
        "          #Doing weighted classes before L1 but might need to do after if not working right\n",
        "          gradient *= classWeightsValues\n",
        "\n",
        "          #Use L1 regularization, I think it works better here for removing uneeded features\n",
        "          L1 = numpy.sign(self.weights)\n",
        "          L1Lambda = 0.01 #Starting point may change to parameter\n",
        "          gradient +=  L1Lambda * L1\n",
        "\n",
        "\n",
        "          self.weights -= self.learning_rate * gradient\n",
        "          ceLoss = -(numpy.sum(logProbs* yHot) / len(logits))\n",
        "          print(f\"Loss: {ceLoss}\")\n",
        "\n",
        "        print('SUCCESS')\n",
        "\n",
        "\n",
        "    def predict(self, test_data_csv: str) -> numpy.ndarray:\n",
        "        \"\"\"\n",
        "        Predict class labels for test data using the trained multinomial logistic regression model.\n",
        "\n",
        "        Loads the test data from a CSV file into a pandas DataFrame. Then, computes the softmax probabilities for each\n",
        "        class using the dot product of the feature matrix and the model weights. The class label for each instances is\n",
        "        predicted based on the highest probability using argmax.\n",
        "\n",
        "        Parameters:\n",
        "            test_data_csv (str): File path to the CSV file containing test data.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Predicted class labels for the test data.\n",
        "        \"\"\"\n",
        "        test_data = pandas.read_csv(test_data_csv)\n",
        "        features = test_data.iloc[:,1:-1].values\n",
        "        allClassesTotal = self.training_data.iloc[:, -1]\n",
        "\n",
        "        #Map NER classes to ints, think I need this for multi logistic regression to work (may also need to fix PER since is combined right now)\n",
        "        uniqueClassNamesSorted = sorted(allClassesTotal.unique())\n",
        "        classMap = {className: i for i, className in enumerate(uniqueClassNamesSorted)}\n",
        "        self.training_data['NERint'] = allClassesTotal.map(classMap)\n",
        "        classes = self.training_data['NERint'].values\n",
        "\n",
        "        self.trueLabels = classes\n",
        "\n",
        "        #Find probs\n",
        "        logits = numpy.dot(features, self.weights)\n",
        "        prob = self.softmax(logits)\n",
        "\n",
        "        #Argmax to get highest prob for prediction\n",
        "        pred = numpy.argmax(prob, axis=1) #Take largest prob for prediction Maybe store so can be used in report\n",
        "        self.predictions = pred\n",
        "        return pred\n",
        "\n",
        "    def generate_report(self) -> None:\n",
        "      \"\"\"\n",
        "      Generate a classification report using scikit learn, base the logic off the library verison\n",
        "      This fucntion acts as a wrapper for classification report as instructed\n",
        "\n",
        "          Parameters:\n",
        "              None\n",
        "\n",
        "          Returns:\n",
        "              None\n",
        "      \"\"\"\n",
        "      if self.trueLabels is None or self.predictions is None:\n",
        "        raise ValueError(\"Cannot generate report before making predictions\")\n",
        "\n",
        "      trueLabels = self.trueLabels\n",
        "      predLabels = self.predictions\n",
        "\n",
        "      uniqueClassNamesSorted = sorted(self.training_data.iloc[:, -2].unique(), reverse=True) #Should give back classes in right order, use -2 now since new col adde\n",
        "\n",
        "      print(uniqueClassNamesSorted)\n",
        "      print(classification_report(trueLabels, predLabels, target_names=uniqueClassNamesSorted))"
      ],
      "metadata": {
        "id": "fOZznbUPWkv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KOdRTD_HX9gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_dataframe(ActionType.TRAIN, 'train_set.csv')\n",
        "create_dataframe(ActionType.TEST, 'test_set.csv')\n",
        "create_dataframe(ActionType.DEV, 'dev_set.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LHVttN2enaH",
        "outputId": "888af3bc-35e4-4099-9d9a-7ccc9aa85c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS\n",
            "SUCCESS\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "model = MultinomialLogisticRegression(learning_rate=0.01, epochs=10, learning_rate_decay=0, training_data_csv='train_set.csv')\n",
        "model.learn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YdmVEQtesjY",
        "outputId": "8635293c-9743-4433-d513-7f3fdb7aab1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 12.032242930768886\n",
            "Loss: 12.031874806636484\n",
            "Loss: 12.03163689386428\n",
            "Loss: 12.031335646248479\n",
            "Loss: 12.031095234099414\n",
            "Loss: 12.030803578690593\n",
            "Loss: 12.03057437010865\n",
            "Loss: 12.030286259927358\n",
            "Loss: 12.030063488498174\n",
            "Loss: 12.029804744184313\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model testing for DEV\n",
        "predictions: numpy.ndarray = model.predict(test_data_csv='dev_set.csv')"
      ],
      "metadata": {
        "id": "or8FzMS8MGe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Report for DEV\n",
        "model.generate_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxCV0XHRMGu4",
        "outputId": "742a9d64-dc55-45b7-c863-09cc6be75a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'I-PER', 'I-ORG', 'I-MISC', 'I-LOC', 'B-ORG', 'B-MISC', 'B-LOC']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.78      0.84      0.80     16094\n",
            "       I-PER       0.21      0.00      0.01      2458\n",
            "       I-ORG       0.00      0.00      0.00      1298\n",
            "      I-MISC       0.00      0.00      0.00       798\n",
            "       I-LOC       0.00      0.00      0.00       353\n",
            "       B-ORG       0.00      0.00      0.00         4\n",
            "      B-MISC       0.00      0.60      0.00         5\n",
            "       B-LOC       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.64     21011\n",
            "   macro avg       0.12      0.18      0.10     21011\n",
            "weighted avg       0.62      0.64      0.62     21011\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model testing for TEST\n",
        "predictions: numpy.ndarray = model.predict(test_data_csv='test_set.csv')"
      ],
      "metadata": {
        "id": "ZXQcC2_ze29n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Report for TEST\n",
        "model.generate_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH4LGIkGr4Zs",
        "outputId": "85c48182-f43c-4c73-bfc4-3f5e24d78e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'I-PER', 'I-ORG', 'I-MISC', 'I-LOC', 'B-ORG', 'B-MISC', 'B-LOC']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.77      0.85      0.81     16094\n",
            "       I-PER       0.11      0.00      0.00      2458\n",
            "       I-ORG       0.00      0.00      0.00      1298\n",
            "      I-MISC       0.00      0.00      0.00       798\n",
            "       I-LOC       0.00      0.00      0.00       353\n",
            "       B-ORG       0.00      0.00      0.00         4\n",
            "      B-MISC       0.00      0.60      0.00         5\n",
            "       B-LOC       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65     21011\n",
            "   macro avg       0.11      0.18      0.10     21011\n",
            "weighted avg       0.60      0.65      0.62     21011\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reporting the results of a multiclass classification is a little more complicated than binary classification. For this part, [please read the documentation of scikit-learn's `classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
        "\n",
        "Then, add an instance method called `generate_report` to the above class. This method should take no arguments (other than the default `self`), and print the report for your classification results in the same format as shown in the above documentation. That is, for a 3-class classification, it should print (shown with dummy results):\n",
        "\n",
        "```\n",
        "                precision    recall  f1-score   support\n",
        "\n",
        "     class 0       0.50      1.00      0.67         1\n",
        "     class 1       0.00      0.00      0.00         1\n",
        "     class 2       1.00      0.67      0.80         3\n",
        "\n",
        "    accuracy                           0.60         5\n",
        "   macro avg       0.50      0.56      0.49         5\n",
        "   micro avg       1.00      0.67      0.80         5\n",
        "```\n",
        "\n",
        "In your generated report, the class names must be the actual labels (e.g., `I-PER`) and not just numbers or indices. As you may have realized, your method will simply be a wrapper around scikit-learn's `classification_report`, but you will have to carefully think about the parameter values to use.\n",
        "\n",
        "**Note:** You are not responsible for generating a report if a user calls this method before testing (by a call to the `predict` function). If a user does invoke `generate_report` without invoking `predict` first, it is acceptable for your code to raise an error."
      ],
      "metadata": {
        "id": "xoKCA6kTirOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your insights [20 points]\n",
        "\n",
        "## 1. Test set vs Dev set: Binary classification [4 points]\n",
        "\n",
        "For the binary classification task, how much does the performance (in terms of each metric) differ between the dev set and the final test set?\n",
        "\n",
        "Between the dev set and the final test set it seems that our dev set performs much better overall. Our precision is about 0.08 better in the dev set, recall is about 0.01 better and f1-score is about 0.04 better.\n",
        "\n",
        "What do you think are the causes behind these differences?\n",
        "\n",
        "I believe that a cause for these differences is that our vocabulary obtained from the training set has more in common to our dev set then our test set. This leads to many of our tokens being defined as UNK giving us a worse performance and words that have been seen are easier to correctly identify in the correct class. Also we try to maximize the results of our dev set so in doing so we should almost always expect our dev set result to be higher because of this.\n",
        "\n",
        "Suggest one or two experiments that you should design and conduct, in order to test your hypothesis (i.e., in order to test whether your answer to the above question is, indeed, correct).\n",
        "\n",
        "I am going to get the overlap in vocabulary between the training set and dev set and training set and test set and compare them. After testing them below I have determined that this is in fact true. The dev set contains 6147 unique overlaping words and the test set contains only 5281 unique overlaping words meaning that the dev set has nearly 1000 more overlapping words making it possibly easier to predict seen words. This could also mean that our test and dev set are more related (discussing similar topics) and our test set may be different from the two. Aditionally, if we tried to maximize the results of our test set before we looked at thse dev set we may be able to get a higher test set than dev set.\n",
        "\n",
        "\n",
        "## 2. Stochastic Gradient Descent [10 points]\n",
        "\n",
        "What exactly is an epoch?\n",
        "\n",
        "An epoch is a complete pass through of all the training data one time. So 100 epochs would be a complete pass through of all of our data 100 times.\n",
        "\n",
        "Why is it important to optimize over multiple epochs, when in each epoch, the training is happening over the same data?\n",
        "\n",
        "When training over multiple epochs we are continually changing our weights using our training data to attempt to minimize our loss function. Doing multiple epochs will let our model converge to a point where it can't minimize the loss function anymore.\n",
        "\n",
        "For the binary classification task, what regularization did you choose when optimizing? Why did you choose this, and not any other?\n",
        "\n",
        "For binary classification task I used L1 regularization or Lasso regression when optimizing. I chose this and not L2 regularization since after doing further research L1 regularization helps with feature selection by shrinking unnessarcy features to 0. I thought this would be helpful for this problem since in my eyes only some of the features I used would contribute more to classification and some may not contribute at all and by doing this it may make our model simpler.\n",
        "\n",
        "For the multiclass classification task, what regularization did you choose when optimizing? Why did you choose this, and not any other?\n",
        "\n",
        "For multiclass classification task I used L1 regularization or Lasso regression when optimizing just like binary classification. I thought this would be helpful for this problem just like binary classification since in my eyes only some of the features I used would contribute more to classification and some of the features I used would just further complicate the model. By using L1 I am helping the model remove unnessarcy features.\n",
        "\n",
        "What types of learning rate decay were included in your experiments (as discussed in the lecture before Spring break)? Did the dev set play an important role in these experiments? Briefly explain how. Also briefly explain what made you fix the type of learning rate decay when testing on the final test set.\n",
        "\n",
        "* Note that this question is about the *type* of decay, not the value of the learning rate or the value of the decay parameter.\n",
        "\n",
        "The type of learning rate decay that were used was time based learnning decay where I limit the learning after each iteration. The dev set played in important role in these experiements because it allowed me to mess around with different parameters to try to maximize my results without over fitting the test set since I hadn't looked at it yet. On the final test I choose to not alter decay because I didnt want to overfit my model on the test data.\n",
        "\n",
        "## 3. Multiclass classification [6 points]\n",
        "\n",
        "Were there any classes that were particularly hard to detect?\n",
        "\n",
        "Most of the classes other than O were hard for my model to dectect, my model detected some of the I-PER aswell but not the best.\n",
        "\n",
        "Why do you think these classes were comparatively more difficult to identify correctly?\n",
        "\n",
        "These classes were comparatively more difficult to identify correctly because we can see the training set had less data to train on for those classes. For B-LOC, B-MISC, and B-ORG there where only 3, 2 and 4 samples respectively in the training set. Even trying to weight the classes to help with the imbalance didn't really help because there are barley any samples to learn off of.\n",
        "\n",
        "What experiments would you design and conduct to try and improve the performance on these difficult categories? Support your answer with technical reasoning (in this context, \"technical\" means either based on mathematical reasoning, linguistic insights, or statistical insights drawn from data).\n",
        "\n",
        "Some things to try would be random under sampling of the majority class to try to help with the class imbalance and would therefore help our model learn each class equally and we could probably expect better results. Additionally, it would help even more if our training data had more data of our under represented classes so our model could learn more about each of them. Right now it is nearly impossible to learn any thing from just a few (1-5) samples of a class, our model needs more information if it is going to learn what features lead to what class.\n"
      ],
      "metadata": {
        "id": "BhNUPSG4mha5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#After reading piazza post it seems like I don't need to implement experiments but will keep this one here anyway since already tried it\n",
        "\n",
        "#Experiment for insight 1\n",
        "trainTokenDict, trainPOSDict = get_vocabulary('/content/eng-ner-dataset/eng.train')\n",
        "devTokenDict, devPOSDict = get_vocabulary('/content/eng-ner-dataset/eng.testa')\n",
        "testTokenDict, testPOSDict = get_vocabulary('/content/eng-ner-dataset/eng.testb')\n",
        "\n",
        "#Get same vocab between train dev and train test\n",
        "\n",
        "commonTrainDev = set(trainTokenDict.keys()) & set(devTokenDict.keys())\n",
        "\n",
        "commonTrainTest = set(trainTokenDict.keys()) & set(testTokenDict.keys())\n",
        "\n",
        "print(f\"Ammount of unique vocab in dev: {len(set(devTokenDict.keys()))}\")\n",
        "print(f\"Ammount of unique vocab in test: {len(set(testTokenDict.keys()))}\")\n",
        "print(f\"Amount of unique vocab in common between train and dev: {len(commonTrainDev)}\")\n",
        "print(f\"Amount of unique vocab in common between train and dev: {len(commonTrainTest)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atI2cwhe5HEC",
        "outputId": "4b1d150f-1450-4dad-b763-4e1d0b07e112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ammount of unique vocab in dev: 9003\n",
            "Ammount of unique vocab in test: 8549\n",
            "Amount of unique vocab in common between train and dev: 6147\n",
            "Amount of unique vocab in common between train and dev: 5281\n"
          ]
        }
      ]
    }
  ]
}